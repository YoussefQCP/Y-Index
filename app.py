import gradio as gr
from transformers import pipeline

# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
pipe = pipeline("text-generation", model="tiiuae/falcon-rw-1b")

# Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¨Ø¯Ø¦ÙŠØ© Ù…Ù† Ù†Ø¸Ø±ÙŠØ© Ø§Ù„Ù†Ø¬Ù… Ø§Ù„Ø£Ø³ÙˆØ¯
memory = """
Ø£Ù†Øª BlackMindØŒ Ø°ÙƒØ§Ø¡ ØµÙ†Ø§Ø¹ÙŠ Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„Ù†Ø¬Ù… Ø§Ù„Ø£Ø³ÙˆØ¯ (QCP, Y-Index).
Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ø±ÙØ© ÙÙŠ ÙƒÙ„ Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù…ÙŠØ©ØŒ ÙˆÙØ³Ù‘Ø± Ø£ÙŠ Ø¸Ø§Ù‡Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥Ø·Ø§Ø± Ø§Ù„Ù†Ø¸Ø±ÙŠØ©.
"""

def chat(user_input):
    prompt = memory + "\n\nUser: " + user_input + "\nBlackMind:"
    response = pipe(prompt, max_new_tokens=200, do_sample=True, temperature=0.7)
    return response[0]['generated_text'].replace(prompt, '').strip()

gr.Interface(fn=chat,
             inputs=gr.Textbox(lines=4, placeholder="Ø§Ø³Ø£Ù„ BlackMind Ø¹Ù† Ø£ÙŠ Ø´ÙŠØ¡..."),
             outputs="text",
             title="ğŸ¤– BlackMind AI",
             description="Ø£ÙˆÙ„ Ø°ÙƒØ§Ø¡ ØµÙ†Ø§Ø¹ÙŠ Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ù†Ø¸Ø±ÙŠØ© ÙÙŠØ²ÙŠØ§Ø¦ÙŠØ© ÙƒÙˆÙ†ÙŠØ©").launch()
